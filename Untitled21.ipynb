{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQ8QlPdbo3ACIge2DcSYy5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejgithubpatil/Assign.-1.1-Edyoda/blob/main/Untitled21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def parse_target_config(json_data):\n",
        "    # Extracting the 'target' section from the JSON\n",
        "    target_config = json_data.get(\"target\", {})\n",
        "\n",
        "    # Reading the required information\n",
        "    prediction_type = target_config.get(\"prediction_type\", \"Not specified\")\n",
        "    target_variable = target_config.get(\"target\", \"Not specified\")\n",
        "    regression_type = target_config.get(\"type\", \"Not specified\")\n",
        "    partitioning = target_config.get(\"partitioning\", False)\n",
        "\n",
        "    # Printing the extracted information\n",
        "    print(f\"Prediction Type: {prediction_type}\")\n",
        "    print(f\"Target Variable: {target_variable}\")\n",
        "    print(f\"Regression Type: {regression_type}\")\n",
        "    print(f\"Partitioning Enabled: {partitioning}\")\n",
        "\n",
        "# Example JSON input\n",
        "json_input = \"\"\"\n",
        "{\n",
        "  \"target\": {\n",
        "    \"prediction_type\": \"Regression\",\n",
        "    \"target\": \"petal_width\",\n",
        "    \"type\": \"regression\",\n",
        "    \"partitioning\": true\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Parse the provided JSON\n",
        "json_data = json.loads(json_input)\n",
        "parse_target_config(json_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eISRywJQ2eQ",
        "outputId": "48c4ce28-2ddf-480a-f987-f576d96662d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction Type: Regression\n",
            "Target Variable: petal_width\n",
            "Regression Type: regression\n",
            "Partitioning Enabled: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Your JSON input as a string\n",
        "json_input = \"\"\"\n",
        "{\n",
        "  \"feature_handling\": {\n",
        "    \"sepal_length\": {\n",
        "      \"feature_name\": \"sepal_length\",\n",
        "      \"is_selected\": true,\n",
        "      \"feature_variable_type\": \"numerical\",\n",
        "      \"feature_details\": {\n",
        "        \"numerical_handling\": \"Keep as regular numerical feature\",\n",
        "        \"rescaling\": \"No rescaling\",\n",
        "        \"make_derived_feats\": false,\n",
        "        \"missing_values\": \"Impute\",\n",
        "        \"impute_with\": \"Average of values\",\n",
        "        \"impute_value\": 0\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Parse the JSON input to get the configuration\n",
        "feature_config = json.loads(json_input)\n",
        "\n",
        "# Function to apply imputation based on the feature configuration\n",
        "def apply_imputation(df, feature_config):\n",
        "    for feature, config in feature_config[\"feature_handling\"].items():\n",
        "        if config[\"feature_details\"][\"missing_values\"] == \"Impute\":\n",
        "            if config[\"feature_details\"][\"impute_with\"] == \"Average of values\":\n",
        "                # Calculate the average without considering NaN values\n",
        "                avg_value = df[feature].mean()\n",
        "                # Fill NaN values with the calculated average\n",
        "                df[feature].fillna(avg_value, inplace=True)\n",
        "            # Extend this block to handle other imputation methods as needed\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/iris.csv')\n",
        "\n",
        "# Apply the imputation to the DataFrame based on the configuration\n",
        "apply_imputation(df, feature_config)\n",
        "\n",
        "# Display the DataFrame to verify the imputation\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYDSaw_0RYKY",
        "outputId": "33d10ab0-d939-40d7-8c5e-1ed7e8e12b20"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width         species\n",
            "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
            "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
            "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
            "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
            "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
            "..            ...          ...           ...          ...             ...\n",
            "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
            "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
            "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
            "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
            "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Assuming df is your DataFrame and target_variable is your target column's name\n",
        "def apply_feature_reduction(df, target_variable, config):\n",
        "    method = config[\"feature_reduction_method\"]\n",
        "    reduced_df = df.copy()\n",
        "\n",
        "    # No Reduction\n",
        "    if config[\"No Reduction\"][\"is_selected\"]:\n",
        "        # Assuming 'No Reduction' simply means limiting the number of features without any specific method\n",
        "        num_features = config[\"No Reduction\"][\"num_of_features_to_keep\"]\n",
        "        reduced_df = reduced_df.iloc[:, :num_features]\n",
        "\n",
        "    # Correlation with Target\n",
        "    elif config[\"Correlation with target\"][\"is_selected\"]:\n",
        "        num_features = config[\"Correlation with target\"][\"num_of_features_to_keep\"]\n",
        "        corr_scores = {col: pearsonr(df[col], df[target_variable])[0] for col in df.columns if df[col].dtype != 'object' and col != target_variable}\n",
        "        sorted_features = sorted(corr_scores, key=corr_scores.get, reverse=True)[:num_features]\n",
        "        reduced_df = df[sorted_features + [target_variable]]\n",
        "\n",
        "    # Tree-based\n",
        "    elif config[\"Tree-based\"][\"is_selected\"]:\n",
        "        num_features = config[\"Tree-based\"][\"num_of_features_to_keep\"]\n",
        "        clf = ExtraTreesClassifier(n_estimators=config[\"Tree-based\"][\"num_of_trees\"])\n",
        "        clf = clf.fit(df.drop(target_variable, axis=1), df[target_variable])\n",
        "        importances = clf.feature_importances_\n",
        "        indices = np.argsort(importances)[::-1][:num_features]\n",
        "        selected_features = df.columns[indices]\n",
        "        reduced_df = df[selected_features.tolist() + [target_variable]]\n",
        "\n",
        "    # PCA\n",
        "    elif config[\"Principal Component Analysis\"][\"is_selected\"]:\n",
        "        num_features = config[\"Principal Component Analysis\"][\"num_of_features_to_keep\"]\n",
        "        pca = PCA(n_components=num_features)\n",
        "        principalComponents = pca.fit_transform(df.drop(target_variable, axis=1))\n",
        "        reduced_df = pd.DataFrame(data = principalComponents, columns = [f'PC{i}' for i in range(1, num_features + 1)])\n",
        "        reduced_df[target_variable] = df[target_variable]\n",
        "\n",
        "    return reduced_df\n",
        "\n",
        "# Example usage:\n",
        "json_config = {\n",
        "  \"feature_reduction_method\": \"Correlation with target\",\n",
        "  \"No Reduction\": {\"is_selected\": True, \"num_of_features_to_keep\": 5},\n",
        "  \"Correlation with target\": {\"is_selected\": False, \"num_of_features_to_keep\": 8},\n",
        "  \"Tree-based\": {\"is_selected\": False, \"num_of_features_to_keep\": 0, \"depth_of_trees\": 0, \"num_of_trees\": 0},\n",
        "  \"Principal Component Analysis\": {\"is_selected\": False, \"num_of_features_to_keep\": 0},\n",
        "}\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('iris.csv')\n",
        "target_variable = 'YourTargetColumnNameHere'\n",
        "\n",
        "# Apply feature reduction\n",
        "reduced_df = apply_feature_reduction(df, target_variable, json_config)\n",
        "\n",
        "# Check the result\n",
        "print(reduced_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx_ovuh7Rc3r",
        "outputId": "8fabc536-9735-4792-aad1-3e9fa1472913"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width      species\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "\n",
        "# Sample JSON configuration\n",
        "json_config = \"\"\"\n",
        "{\n",
        "  \"prediction_type\": \"Classification\",\n",
        "  \"models\": {\n",
        "    \"LogisticRegression\": {\n",
        "      \"model_name\": \"LogisticRegression\",\n",
        "      \"is_selected\": true,\n",
        "      \"parallelism\": 2,\n",
        "      \"min_iter\": 30,\n",
        "      \"max_iter\": 50,\n",
        "      \"min_regparam\": 0.5,\n",
        "      \"max_regparam\": 0.8,\n",
        "      \"min_elasticnet\": 0.5,\n",
        "      \"max_elasticnet\": 0.8\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Function to parse JSON and instantiate models\n",
        "def instantiate_model_from_json(json_str):\n",
        "    config = json.loads(json_str)\n",
        "    models = []\n",
        "\n",
        "    if config[\"prediction_type\"] == \"Classification\":\n",
        "        # For each model configuration\n",
        "        for model_name, model_config in config[\"models\"].items():\n",
        "            if model_config[\"is_selected\"]:\n",
        "                if model_name == \"LogisticRegression\":\n",
        "                    # Example: Instantiate logistic regression with averaged parameters\n",
        "                    # Adjust the instantiation as needed based on the parameters you want to use\n",
        "                    lr = LogisticRegression(\n",
        "                        max_iter=int((model_config[\"min_iter\"] + model_config[\"max_iter\"]) / 2),\n",
        "                        C=1.0 / ((model_config[\"min_regparam\"] + model_config[\"max_regparam\"]) / 2),  # Inverse of regularization strength\n",
        "                        # L1 ratio or other parameters related to elastic net can be set similarly\n",
        "                    )\n",
        "                    models.append(lr)\n",
        "                # Extend with elif blocks for other classification models as needed\n",
        "    elif config[\"prediction_type\"] == \"Regression\":\n",
        "        # Instantiate regression models similarly, for example:\n",
        "        pass  # Add logic for regression models here\n",
        "\n",
        "    return models\n",
        "\n",
        "# Example usage\n",
        "models = instantiate_model_from_json(json_config)\n",
        "for model in models:\n",
        "    print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL87atZFRq8J",
        "outputId": "8cd2651c-491e-4898-904f-429b94fd98e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1.5384615384615383, max_iter=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X_train = np.random.rand(100, 10)\n",
        "y_train = np.random.rand(100)\n",
        "X_test = np.random.rand(50, 10)\n",
        "y_test=np.random.rand(50)\n",
        "\n",
        "# Define models and their parameter grids\n",
        "models = {\n",
        "    \"RandomForest\": (RandomForestRegressor(), {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20]}),\n",
        "    \"SVR\": (SVR(), {'kernel': ['linear', 'rbf'], 'C': [0.1, 1, 10]}),\n",
        "    \"LinearRegression\": (LinearRegression(), {'fit_intercept': [True, False]})\n",
        "}\n",
        "\n",
        "# TimeSeriesSplit cross-validation with overlap\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Iterate through each model, perform GridSearchCV, and fit the data\n",
        "for name, (model, param_grid) in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=tscv)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "    print(f\"Best score for {name}: {grid_search.best_score_}\")\n",
        "\n",
        "    # Predict using the best estimator obtained from GridSearchCV\n",
        "    predictions = grid_search.predict(X_test)\n",
        "    print(f\"Predictions for {name}: {predictions}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McEJE6E5RvUt",
        "outputId": "fe823d74-15ef-4519-a158-bacc8f239b58"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for RandomForest: {'max_depth': 20, 'n_estimators': 50}\n",
            "Best score for RandomForest: -0.11080410445974882\n",
            "Predictions for RandomForest: [0.31127929 0.63283338 0.55270256 0.62737702 0.48813515 0.34362644\n",
            " 0.52960549 0.53748534 0.41517443 0.6687627  0.59806387 0.45033455\n",
            " 0.40155808 0.50302051 0.44634002 0.48560242 0.42475764 0.49404163\n",
            " 0.40222945 0.62815233 0.74236982 0.48092169 0.19228671 0.46223819\n",
            " 0.56131671 0.67882449 0.55254588 0.45561322 0.52136918 0.33457194\n",
            " 0.55741531 0.64269329 0.63437758 0.70505503 0.45912581 0.51011481\n",
            " 0.52794935 0.23889772 0.52757581 0.47672235 0.61177956 0.3894702\n",
            " 0.48869331 0.53779374 0.43507491 0.49666006 0.50212132 0.649043\n",
            " 0.37524112 0.2825737 ]\n",
            "Best parameters for SVR: {'C': 0.1, 'kernel': 'rbf'}\n",
            "Best score for SVR: -0.18066619545849572\n",
            "Predictions for SVR: [0.38861579 0.49708479 0.51240723 0.56892599 0.45548634 0.48224971\n",
            " 0.59453796 0.61634212 0.43070437 0.67569887 0.57461447 0.50693144\n",
            " 0.51832838 0.54209325 0.37555689 0.47670153 0.36144139 0.52945419\n",
            " 0.40917519 0.48993155 0.56850863 0.41888937 0.35542254 0.48822091\n",
            " 0.52856566 0.5951866  0.49594646 0.56816075 0.42651807 0.35418791\n",
            " 0.53456746 0.51112149 0.46258084 0.54958454 0.41016234 0.53420741\n",
            " 0.41777725 0.34702771 0.50503808 0.55395338 0.57142973 0.34050411\n",
            " 0.41048514 0.530234   0.51174571 0.60666595 0.48269473 0.54719553\n",
            " 0.39329727 0.35965853]\n",
            "Best parameters for LinearRegression: {'fit_intercept': True}\n",
            "Best score for LinearRegression: -0.929041664131457\n",
            "Predictions for LinearRegression: [0.36090234 0.63375189 0.5556087  0.5710912  0.36235439 0.46201266\n",
            " 0.68911142 0.66067942 0.38159782 0.68929292 0.55243205 0.59070344\n",
            " 0.49334116 0.55055048 0.32617036 0.45376269 0.27837331 0.49807734\n",
            " 0.45190742 0.58846332 0.55747094 0.42519158 0.23443503 0.51398716\n",
            " 0.59623498 0.63872036 0.57798563 0.53610761 0.31437188 0.31645984\n",
            " 0.67314739 0.56797304 0.54564159 0.79151359 0.34235796 0.50438774\n",
            " 0.45784125 0.25040343 0.51922268 0.56432412 0.66836238 0.34901722\n",
            " 0.34838968 0.47102224 0.44431963 0.71063203 0.44937228 0.61934407\n",
            " 0.29450767 0.31120205]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Iterate through each model, perform GridSearchCV, and fit the data\n",
        "for name, (model, param_grid) in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=tscv)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "    print(f\"Best score for {name}: {grid_search.best_score_}\")\n",
        "\n",
        "    # Predict using the best estimator obtained from GridSearchCV\n",
        "    predictions = grid_search.predict(X_test)\n",
        "    print(f\"Predictions for {name}: {predictions}\")\n",
        "\n",
        "    # Evaluate model performance\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "\n",
        "    print(f\"Mean Absolute Error for {name}: {mae}\")\n",
        "    print(f\"Mean Squared Error for {name}: {mse}\")\n",
        "    print(f\"R-squared for {name}: {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeTanE_yR02w",
        "outputId": "1933b422-6288-422c-f847-075c17802643"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for RandomForest: {'max_depth': None, 'n_estimators': 100}\n",
            "Best score for RandomForest: -0.13617350370612255\n",
            "Predictions for RandomForest: [0.38422456 0.57745005 0.54423797 0.62827464 0.53064866 0.48419815\n",
            " 0.5544912  0.53618355 0.4632348  0.69244414 0.59660725 0.40791109\n",
            " 0.48766426 0.54793429 0.50301267 0.52744341 0.40845855 0.46714596\n",
            " 0.42249439 0.63465852 0.68667888 0.58718195 0.2303024  0.46494558\n",
            " 0.50634027 0.60960243 0.50280574 0.60039646 0.56753026 0.34282348\n",
            " 0.49230702 0.62529045 0.55358786 0.59507402 0.46989455 0.68809485\n",
            " 0.54362981 0.28193054 0.52935598 0.61497949 0.64076518 0.377864\n",
            " 0.49361318 0.47722327 0.54673838 0.51622719 0.55270438 0.64924743\n",
            " 0.36982652 0.40520547]\n",
            "Mean Absolute Error for RandomForest: 0.27893093510696454\n",
            "Mean Squared Error for RandomForest: 0.1030905830693722\n",
            "R-squared for RandomForest: -0.4121583195373999\n",
            "Best parameters for SVR: {'C': 0.1, 'kernel': 'rbf'}\n",
            "Best score for SVR: -0.18066619545849572\n",
            "Predictions for SVR: [0.38861579 0.49708479 0.51240723 0.56892599 0.45548634 0.48224971\n",
            " 0.59453796 0.61634212 0.43070437 0.67569887 0.57461447 0.50693144\n",
            " 0.51832838 0.54209325 0.37555689 0.47670153 0.36144139 0.52945419\n",
            " 0.40917519 0.48993155 0.56850863 0.41888937 0.35542254 0.48822091\n",
            " 0.52856566 0.5951866  0.49594646 0.56816075 0.42651807 0.35418791\n",
            " 0.53456746 0.51112149 0.46258084 0.54958454 0.41016234 0.53420741\n",
            " 0.41777725 0.34702771 0.50503808 0.55395338 0.57142973 0.34050411\n",
            " 0.41048514 0.530234   0.51174571 0.60666595 0.48269473 0.54719553\n",
            " 0.39329727 0.35965853]\n",
            "Mean Absolute Error for SVR: 0.26602017291306684\n",
            "Mean Squared Error for SVR: 0.0917300582765258\n",
            "R-squared for SVR: -0.2565392598437197\n",
            "Best parameters for LinearRegression: {'fit_intercept': True}\n",
            "Best score for LinearRegression: -0.929041664131457\n",
            "Predictions for LinearRegression: [0.36090234 0.63375189 0.5556087  0.5710912  0.36235439 0.46201266\n",
            " 0.68911142 0.66067942 0.38159782 0.68929292 0.55243205 0.59070344\n",
            " 0.49334116 0.55055048 0.32617036 0.45376269 0.27837331 0.49807734\n",
            " 0.45190742 0.58846332 0.55747094 0.42519158 0.23443503 0.51398716\n",
            " 0.59623498 0.63872036 0.57798563 0.53610761 0.31437188 0.31645984\n",
            " 0.67314739 0.56797304 0.54564159 0.79151359 0.34235796 0.50438774\n",
            " 0.45784125 0.25040343 0.51922268 0.56432412 0.66836238 0.34901722\n",
            " 0.34838968 0.47102224 0.44431963 0.71063203 0.44937228 0.61934407\n",
            " 0.29450767 0.31120205]\n",
            "Mean Absolute Error for LinearRegression: 0.2855043174505084\n",
            "Mean Squared Error for LinearRegression: 0.11002282410725302\n",
            "R-squared for LinearRegression: -0.5071177383632146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lj-h67HqSELF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W1rm4FfETCVk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YhwbR5s1TpmN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}